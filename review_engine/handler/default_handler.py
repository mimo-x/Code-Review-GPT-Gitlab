import concurrent.futures
import threading

from retrying import retry

from config.config import gpt_message
from review_engine.abstract_handler import ReviewHandle
from utils.gitlab_parser import filter_diff_content
from utils.logger import log


def chat_review(changes, model):
    log.info('å¼€å§‹code review')
    with concurrent.futures.ThreadPoolExecutor() as executor:
        review_results = []
        result_lock = threading.Lock()

        def process_change(change):
            result = generate_review_note(change, model)
            with result_lock:
                review_results.append(result)

        futures = []
        for change in changes:
            if any(change["new_path"].endswith(ext) for ext in ['.py', '.java', '.class', '.vue', ".go"]) and not any(
                change["new_path"].endswith(ext) for ext in ["mod.go"]):
                futures.append(executor.submit(process_change, change))
            else:
                log.info(f"{change['new_path']} éç›®æ ‡æ£€æµ‹æ–‡ä»¶ï¼")

        concurrent.futures.wait(futures)

    return "\n\n".join(review_results) if review_results else ""

@retry(stop_max_attempt_number=3, wait_fixed=60000)
def generate_review_note(change, model):
    try:
        content = filter_diff_content(change['diff'])
        messages = [
            {"role": "system",
             "content": gpt_message
             },
            {"role": "user",
             "content": f"è¯·reviewè¿™éƒ¨åˆ†ä»£ç å˜æ›´{content}",
             },
        ]
        log.info(f"å‘é€ç»™gpt å†…å®¹å¦‚ä¸‹ï¼š{messages}")
        model.generate_text(messages)
        new_path = change['new_path']
        log.info(f'å¯¹ {new_path} reviewä¸­...')
        response_content = model.get_respond_content().replace('\n\n', '\n')
        total_tokens = model.get_respond_tokens()
        review_note = f'# ğŸ“š`{new_path}`' + '\n\n'
        review_note += f'({total_tokens} tokens) {"AI review æ„è§å¦‚ä¸‹:"}' + '\n\n'
        review_note += response_content + """
    ----
    ----
    ----
    ----
    ----
    ----
    ----
        """
        log.info(f'å¯¹ {new_path} reviewç»“æŸ')
        return review_note
    except Exception as e:
        log.error(f"GPT error:{e}")


class MainReviewHandle(ReviewHandle):
    def merge_handle(self, changes, merge_info, hook_info, reply, model):
        self.default_handle(changes, merge_info, hook_info, reply, model)

    def default_handle(self, changes, merge_info, hook_info, reply, model):
        maximum_files = 50
        if changes and len(changes) <= maximum_files:
            # Code Review ä¿¡æ¯
            review_info = chat_review(changes, model)
            if review_info:
                reply.add_reply({
                    'content': review_info,
                    'msg_type': 'MAIN, SINGLE',
                    'target': 'all',
                })
                reply.add_reply({
                    'title': '__MAIN_REVIEW__',
                    'content': (
                        f"## é¡¹ç›®åç§°: **{hook_info['project']['name']}**\n\n"
                        f"### åˆå¹¶è¯·æ±‚è¯¦æƒ…\n"
                        f"- **MR URL**: [æŸ¥çœ‹åˆå¹¶è¯·æ±‚]({hook_info['object_attributes']['url']})\n"
                        f"- **æºåˆ†æ”¯**: `{hook_info['object_attributes']['source_branch']}`\n"
                        f"- **ç›®æ ‡åˆ†æ”¯**: `{hook_info['object_attributes']['target_branch']}`\n\n"
                        f"### å˜æ›´è¯¦æƒ…\n"
                        f"- **ä¿®æ”¹æ–‡ä»¶ä¸ªæ•°**: `{len(changes)}`\n"
                        f"- **Code Review çŠ¶æ€**: âœ…\n"
                    ),
                    'target': 'dingtalk',
                    'msg_type': 'MAIN, SINGLE',
                })
            else:
                reply.add_reply({
                    'title': '__MAIN_REVIEW__',
                    'content': (
                        f"## é¡¹ç›®åç§°: **{hook_info['project']['name']}**\n\n"
                        f"### åˆå¹¶è¯·æ±‚è¯¦æƒ…\n"
                        f"- **MR URL**: [æŸ¥çœ‹åˆå¹¶è¯·æ±‚]({hook_info['object_attributes']['url']})\n"
                        f"- **æºåˆ†æ”¯**: `{hook_info['object_attributes']['source_branch']}`\n"
                        f"- **ç›®æ ‡åˆ†æ”¯**: `{hook_info['object_attributes']['target_branch']}`\n\n"
                        f"### å˜æ›´è¯¦æƒ…\n"
                        f"- **ä¿®æ”¹æ–‡ä»¶ä¸ªæ•°**: `{len(changes)}`\n"
                        f"- **å¤‡æ³¨**: å­˜åœ¨å·²ç»æäº¤çš„ MRï¼Œæ‰€æœ‰æ–‡ä»¶å·²è¿›è¡Œ MR\n"
                        f"- **Code Review çŠ¶æ€**: pass âœ…\n"
                    ),
                    'target': 'dingtalk',
                    'msg_type': 'MAIN, SINGLE',
                })


        elif changes and len(changes) > maximum_files:
            reply.add_reply({
                'title': '__MAIN_REVIEW__',
                'content': (
                    f"## é¡¹ç›®åç§°: **{hook_info['project']['name']}**\n\n"
                    f"### å¤‡æ³¨\n"
                    f"ä¿®æ”¹ `{len(changes)}` ä¸ªæ–‡ä»¶ > 50 ä¸ªæ–‡ä»¶ï¼Œä¸è¿›è¡Œ Code Review âš ï¸\n\n"
                    f"### åˆå¹¶è¯·æ±‚è¯¦æƒ…\n"
                    f"- **MR URL**: [æŸ¥çœ‹åˆå¹¶è¯·æ±‚]({hook_info['object_attributes']['url']})\n"
                    f"- **æºåˆ†æ”¯**: `{hook_info['object_attributes']['source_branch']}`\n"
                    f"- **ç›®æ ‡åˆ†æ”¯**: `{hook_info['object_attributes']['target_branch']}`\n"
                ),
                'target': 'dingtalk',
                'msg_type': 'MAIN, SINGLE',
            })

        else:
            log.error(f"è·å–merge_requestä¿¡æ¯å¤±è´¥ï¼Œproject_id: {hook_info['project']['id']} |"
                      f" merge_iid: {hook_info['object_attributes']['iid']}")

if __name__ == '__main__':
    main_handle = MainReviewHandle()
    from gitlab_integration.gitlab_fetcher import GitlabMergeRequestFetcher
    from reply_module.reply import Reply
    fetcher = GitlabMergeRequestFetcher(9885, 18)
    changes = fetcher.get_changes()
    info = fetcher.get_info()
    reply = Reply({'type': 'merge_request',
                     'project_id': 9885,
                     'merge_request_iid': 18})
    from large_model.llm_generator import LLMGenerator
    model = LLMGenerator.new_model()
    hook_info = {
        "object_kind": "merge_request",
        "event_type": "merge_request",
        "user": {
            "id": 1,
            "name": "John Doe",
            "username": "johndoe",
            "avatar_url": "https://example.com/uploads/user/avatar/1/index.jpg"
        },
        "project": {
            "id": 15,
            "name": "Example Project",
            "description": "An example project",
            "web_url": "https://example.com/example/project",
            "avatar_url": None,
            "git_ssh_url": "git@example.com:example/project.git",
            "git_http_url": "https://example.com/example/project.git",
            "namespace": "Example",
            "visibility_level": 20,
            "path_with_namespace": "example/project",
            "default_branch": "main",
            "homepage": "https://example.com/example/project",
            "url": "https://example.com/example/project.git",
            "ssh_url": "git@example.com:example/project.git",
            "http_url": "https://example.com/example/project.git"
        },
        "object_attributes": {
            "id": 99,
            "iid": 1,
            "target_branch": "main",
            "source_branch": "feature-branch",
            "source_project_id": 15,
            "target_project_id": 15,
            "title": "Merge feature-branch into main",
            "state": "opened",
            "merge_status": "can_be_merged",
            "url": "https://example.com/example/project/-/merge_requests/1",
            "created_at": "2025-02-10T12:34:56Z",
            "updated_at": "2025-02-10T12:34:56Z"
        },
        "changes": {
            "total_changes": 51,
            "files": [
                {"old_path": "file1.txt", "new_path": "file1.txt", "a_mode": "100644", "b_mode": "100644", "diff": "diff content"},
                # ... 50 more file changes ...
            ]
        }
    }
    main_handle.merge_handle(changes, info, hook_info, reply, model)
