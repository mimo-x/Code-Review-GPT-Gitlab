import concurrent.futures
import threading

from retrying import retry
from config.config import GPT_MESSAGE, MAX_FILES
from review_engine.abstract_handler import ReviewHandle
from utils.gitlab_parser import filter_diff_content, add_context_to_diff
from utils.logger import log
from utils.args_check import file_need_check
from utils.tools import create_markdown_table


def chat_review(changes, generate_review, *args, **kwargs):
    log.info('å¼€å§‹code review')
    with concurrent.futures.ThreadPoolExecutor() as executor:
        review_results = []
        result_lock = threading.Lock()

        def process_change(change):
            result = generate_review(change, *args, **kwargs)
            with result_lock:
                review_results.append(result)

        futures = []
        for change in changes:
            if not file_need_check(change["new_path"]):
                log.info(f"{change['new_path']} éç›®æ ‡æ£€æµ‹æ–‡ä»¶ï¼")
                continue
            
            futures.append(executor.submit(process_change, change))

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        concurrent.futures.wait(futures)

    # åˆå¹¶ç»“æœ
    return "\n\n".join(review_results) if review_results else ""

@retry(stop_max_attempt_number=3, wait_fixed=60000)
def chat_review_summary(changes, model):

    summary_note = ""
    diff_list = []
    file_list = []
    # è·å–æ‰€æœ‰diffå’Œå˜æ›´æ–‡ä»¶
    for change in changes:
        diff_list.append(change['diff'])
        file_list.append(change['new_path'])
    for i in range(len(file_list)):
        file_list[i] = f"`{file_list[i]}`<br>"

    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±ç¼–ç¨‹ä¸“å®¶ï¼Œgitlabçš„åˆ†æ”¯ä»£ç å˜æ›´å°†ä»¥git diff å­—ç¬¦ä¸²æ•°ç»„çš„å½¢å¼æä¾›ï¼ŒdiffåŒ…æ‹¬å¤šä¸ªåœ°æ–¹çš„ä»£ç ä¿®æ”¹ï¼Œè¯·ä»ä¸­æå–å‡º\
         ä¸»è¦çš„ä»£ç å˜æ›´ï¼Œå¹¶å°†è¿™äº›å˜æ›´æ€»ç»“ä¸ºä¸€æ®µç®€æ´çš„æè¿°ï¼Œçªå‡ºå…³é”®çš„ä¿®æ”¹å†…å®¹å’Œå…¶å½±å“ï¼Œè¦æ±‚åªè¾“å‡ºä¸€æ®µè¯ï¼Œä¸éœ€è¦åˆ†ç‚¹å›ç­”ã€‚"
        },
        {
            "role": "user",
            "content": f"è¯·reviewè¿™éƒ¨åˆ†ä»£ç å˜æ›´ {diff_list}",
        },
    ]
    log.info("LLM å¯¹ä»£ç å˜æ›´æ€»ç»“ä¸­...")
    model.generate_text(messages)
    response_content = model.get_respond_content().replace('\n\n', '\n')
    log.info("LLM ä»£ç å˜æ›´æ€»ç»“å®Œæˆ")

    # markdown æ€»ç»“è¡¨æ ¼
    headers = ["File(s)", "Change Summary"]
    rows = [
        ["".join(file_list), response_content]
    ]
    markdown_table = create_markdown_table(headers, rows)
    summary_note = f" # â­ æ€»ç»“\n\n {markdown_table} \n\n"
    return summary_note

@retry(stop_max_attempt_number=3, wait_fixed=60000)
def generate_review_note_with_context(change, model, gitlab_fetcher, merge_info):
    try:
        # prepare
        source_code = gitlab_fetcher.get_file_content(change['new_path'], merge_info['source_branch'])
        new_path = change['new_path']
        content = add_context_to_diff(change['diff'], source_code)
        messages = [
            {
                "role": "system",
                "content": GPT_MESSAGE
             },
            {
                "role": "user",
                "content": f"è¯·reviewè¿™éƒ¨åˆ†ä»£ç å˜æ›´ {content}",
            },
        ]
        
        # review
        log.info(f"å‘é€ç»™ LLM å†…å®¹å¦‚ä¸‹ï¼š{messages}")
        model.generate_text(messages)
        log.info(f'å¯¹ {new_path} reviewä¸­...')
        response_content = model.get_respond_content().replace('\n\n', '\n')
        total_tokens = model.get_respond_tokens()
        
        # response 
        review_note = f'# ğŸ“š`{new_path}`' + '\n\n'
        review_note += f'({total_tokens} tokens) {"AI review æ„è§å¦‚ä¸‹:"}' + '\n\n'
        review_note += response_content + "\n\n---\n\n---\n\n"
        
        log.info(f'å¯¹ {new_path} reviewç»“æŸ')
        return review_note
    
    except Exception as e:
        log.error(f"LLM Review error:{e}")
        return ""


class MainReviewHandle(ReviewHandle):
    def merge_handle(self, gitlabMergeRequestFetcher, gitlabRepoManager, hook_info, reply, model):
        changes = gitlabMergeRequestFetcher.get_changes()
        merge_info = gitlabMergeRequestFetcher.get_info()
        self.default_handle(changes, merge_info, hook_info, reply, model, gitlabMergeRequestFetcher)


    def default_handle(self, changes, merge_info, hook_info, reply, model, gitlab_fetcher):
        if changes and len(changes) <= MAX_FILES:
            review_summary = chat_review_summary(changes, model)
            review_info = chat_review(changes, generate_review_note_with_context, model, gitlab_fetcher, merge_info)
            review_info = review_summary + review_info

            if review_info:
                reply.add_reply({
                    'content': review_info,
                    'msg_type': 'MAIN, SINGLE',
                    'target': 'all',
                })
                reply.add_reply({
                    'title': '__MAIN_REVIEW__',
                    'content': (
                        f"## é¡¹ç›®åç§°: **{hook_info['project']['name']}**\n\n"
                        f"### åˆå¹¶è¯·æ±‚è¯¦æƒ…\n"
                        f"- **MR URL**: [æŸ¥çœ‹åˆå¹¶è¯·æ±‚]({hook_info['object_attributes']['url']})\n"
                        f"- **æºåˆ†æ”¯**: `{hook_info['object_attributes']['source_branch']}`\n"
                        f"- **ç›®æ ‡åˆ†æ”¯**: `{hook_info['object_attributes']['target_branch']}`\n\n"
                        f"### å˜æ›´è¯¦æƒ…\n"
                        f"- **ä¿®æ”¹æ–‡ä»¶ä¸ªæ•°**: `{len(changes)}`\n"
                        f"- **Code Review çŠ¶æ€**: âœ…\n"
                    ),
                    'target': 'dingtalk',
                    'msg_type': 'MAIN, SINGLE',
                })
            else:
                reply.add_reply({
                    'title': '__MAIN_REVIEW__',
                    'content': (
                        f"## é¡¹ç›®åç§°: **{hook_info['project']['name']}**\n\n"
                        f"### åˆå¹¶è¯·æ±‚è¯¦æƒ…\n"
                        f"- **MR URL**: [æŸ¥çœ‹åˆå¹¶è¯·æ±‚]({hook_info['object_attributes']['url']})\n"
                        f"- **æºåˆ†æ”¯**: `{hook_info['object_attributes']['source_branch']}`\n"
                        f"- **ç›®æ ‡åˆ†æ”¯**: `{hook_info['object_attributes']['target_branch']}`\n\n"
                        f"### å˜æ›´è¯¦æƒ…\n"
                        f"- **ä¿®æ”¹æ–‡ä»¶ä¸ªæ•°**: `{len(changes)}`\n"
                        f"- **å¤‡æ³¨**: å­˜åœ¨å·²ç»æäº¤çš„ MRï¼Œæ‰€æœ‰æ–‡ä»¶å·²è¿›è¡Œ MR\n"
                        f"- **Code Review çŠ¶æ€**: pass âœ…\n"
                    ),
                    'target': 'dingtalk',
                    'msg_type': 'MAIN, SINGLE',
                })


        elif changes and len(changes) > MAX_FILES:
            reply.add_reply({
                'title': '__MAIN_REVIEW__',
                'content': (
                    f"## é¡¹ç›®åç§°: **{hook_info['project']['name']}**\n\n"
                    f"### å¤‡æ³¨\n"
                    f"ä¿®æ”¹ `{len(changes)}` ä¸ªæ–‡ä»¶ > 50 ä¸ªæ–‡ä»¶ï¼Œä¸è¿›è¡Œ Code Review âš ï¸\n\n"
                    f"### åˆå¹¶è¯·æ±‚è¯¦æƒ…\n"
                    f"- **MR URL**: [æŸ¥çœ‹åˆå¹¶è¯·æ±‚]({hook_info['object_attributes']['url']})\n"
                    f"- **æºåˆ†æ”¯**: `{hook_info['object_attributes']['source_branch']}`\n"
                    f"- **ç›®æ ‡åˆ†æ”¯**: `{hook_info['object_attributes']['target_branch']}`\n"
                ),
                'target': 'dingtalk',
                'msg_type': 'MAIN, SINGLE',
            })

        else:
            log.error(f"è·å–merge_requestä¿¡æ¯å¤±è´¥ï¼Œproject_id: {hook_info['project']['id']} |"
                      f" merge_iid: {hook_info['object_attributes']['iid']}")


